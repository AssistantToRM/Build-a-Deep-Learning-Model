{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96ab83f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9631175",
   "metadata": {},
   "source": [
    "## A. Build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f387d726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Mean of Mean Squared Errors: 338.7213762809644\n",
      "Standard Deviation of Mean Squared Errors: 241.90263932362242\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "file_path = 'concrete_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#separating features/target variable\n",
    "X = data.drop(columns=['Strength'])\n",
    "y = data['Strength']\n",
    "\n",
    "#function for baseline model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#initializing a list to store mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "#repeating process 50 times\n",
    "for _ in range(50):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "    model = baseline_model() #creating model\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0) #training model\n",
    "\n",
    "    #evaluating model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    mse_list.append(mse) #append mean squared error to the list\n",
    "\n",
    "#calculated mean and standard deviation of mean squared errors\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "#printing mean and standard deviation of mean squared errors\n",
    "print(f\"Mean of Mean Squared Errors: {mean_mse}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors: {std_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddd844",
   "metadata": {},
   "source": [
    "## B. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73481e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Mean of Mean Squared Errors (Normalized Data): 359.0386368374318\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "file_path = 'concrete_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#separating features/target variable\n",
    "X = data.drop(columns=['Strength'])\n",
    "y = data['Strength']\n",
    "\n",
    "#normalizing features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#function for baseline model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_normalized.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer with default linear activation\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#initializing a list to store mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "#repeating process 50 times\n",
    "for _ in range(50):\n",
    "    #split normalized data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
    "    \n",
    "    model = baseline_model() #creating model\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0) #training model\n",
    "\n",
    "     \n",
    " #evaluating model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    mse_list.append(mse) #append mean squared error to the list\n",
    "\n",
    "\n",
    "#calculated mean and standard deviation of mean squared errors\n",
    "mean_mse_normalized = np.mean(mse_list)\n",
    "\n",
    "#printing mean of mean squared errors\n",
    "print(f\"Mean of Mean Squared Errors (Normalized Data): {mean_mse_normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453842f",
   "metadata": {},
   "source": [
    "In this comparison, it appears that normalizing the data in Step B resulted in a slightly higher mean of mean squared errors compared to the non-normalized data in Step A. This difference might indicate that, in this specific scenario, normalizing the data didn't significantly improve the model's predictive performance; it might have even led to a slightly worse performance, as indicated by the marginally higher mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c9bb5",
   "metadata": {},
   "source": [
    "## C. Increate the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b9f4d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Mean of Mean Squared Errors (100 epochs): 166.56643398852674\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "file_path = 'concrete_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#separating features/target variable\n",
    "X = data.drop(columns=['Strength'])\n",
    "y = data['Strength']\n",
    "\n",
    "#normalizing features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#function for baseline model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_normalized.shape[1], activation='relu'))\n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#initializing a list to store mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "#repeating process 50 times\n",
    "for _ in range(50):\n",
    "    #split normalized data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
    "    \n",
    "    model = baseline_model() #creating model\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0) #training model with 100 epochs\n",
    "    \n",
    "#evaluating model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    mse_list.append(mse)  #append mean squared error to the list\n",
    "\n",
    "\n",
    "#calculated mean and standard deviation of mean squared errors\n",
    "mean_mse_100_epochs = np.mean(mse_list)\n",
    "\n",
    "#printing mean of mean squared errors for 100 epochs\n",
    "print(f\"Mean of Mean Squared Errors (100 epochs): {mean_mse_100_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af45d6",
   "metadata": {},
   "source": [
    "In Step B (50 epochs), the mean of mean squared errors was approximately 359.04.\n",
    "In Step C (100 epochs), the mean of mean squared errors reduced significantly to approximately 166.57.\n",
    "\n",
    "This reduction suggests that allowing the model to train for a greater number of epochs led to improved performance, resulting in lower error rates when predicting the concrete strength. Increasing the number of epochs provided the model with more opportunities to adjust its weights and improve its predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e43e04",
   "metadata": {},
   "source": [
    "## D. Increase the number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e26c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Mean of Mean Squared Errors (Three Hidden Layers): 132.21949883176055\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "file_path = 'concrete_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#separating features/target variable\n",
    "X = data.drop(columns=['Strength'])\n",
    "y = data['Strength']\n",
    "\n",
    "#normalizing features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#function for baseline model with three hidden layers\n",
    "def three_hidden_layers_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_normalized.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer with default linear activation\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#initializing a list to store mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "#repeating process 50 times\n",
    "for _ in range(50):\n",
    "                            #split normalized data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
    "\n",
    "    #creating model with three hidden layers\n",
    "    model = three_hidden_layers_model()\n",
    "\n",
    "    #training model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "    #evaluating model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    mse_list.append(mse) #appending mean squared error to the list\n",
    "\n",
    "#calculated mean and standard deviation of mean squared errors\n",
    "mean_mse_three_layers = np.mean(mse_list)\n",
    "\n",
    "#printing mean of mean squared errors for three hidden layers\n",
    "print(f\"Mean of Mean Squared Errors (Three Hidden Layers): {mean_mse_three_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa615cbd",
   "metadata": {},
   "source": [
    "In Step B (50 epochs with a single hidden layer), the mean of mean squared errors was approximately 359.04.\n",
    "In Step D (50 epochs with three hidden layers), the mean of mean squared errors reduced significantly to approximately 132.22.\n",
    "\n",
    "The decrease in mean squared error when transitioning from a single hidden layer to three hidden layers suggests that the neural network architecture with multiple hidden layers and 50 epochs performed better in predicting concrete strength. This improvement could be due to the increased complexity and capacity of the network with additional hidden layers, allowing it to capture more intricate relationships within the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
